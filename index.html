<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence</title>
    <link rel="icon" type="image/png" sizes="16x16" href="images/favicon_package/icon.png">

    <link rel="stylesheet" href="css/bootstrap-4.4.1.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="fonts/avenir-next/stylesheet.css">
    <link rel="stylesheet" href="fonts/segoe-print/stylesheet.css">
    <link rel="stylesheet" href="css/window.css">
    <link rel="stylesheet" href="css/carousel.css">
    <link rel="stylesheet" href="css/selection_panel.css">
    <link rel="stylesheet" href="css/main.css">
    <!-- <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"> -->
    <link rel="stylesheet" href="css/bulma-carousel.min.css">
    <link rel="stylesheet" href="css/bulma-slider.min.css">
    <!-- <link rel="stylesheet" href="css/bulma.min.css"> -->
    <link rel="stylesheet" href="css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="css/index.css">

    <script src="js/window.js"></script>
    <script src="js/carousel.js"></script>
    <script src="js/selection_panel.js"></script>
    <script src="js/generation.js"></script>
    <script src="js/editing.js"></script>
    <script src="js/application.js"></script>
    <script src="js/main.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="js/fontawesome.all.min.js"></script>
    <script src="js/bulma-carousel.min.js"></script>
    <script src="js/bulma-slider.min.js"></script>
    <script src="js/index.js"></script>
    <script src="js/video_comparison.js" defer></script>
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2><b><span class="x-gradient-font">RadarLLM</span>: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence</b></h2>
            <h6>
              Zengyuan Lai</a><sup>1,2,*</sup>,
              Jiarui Yang</a><sup>1,*</sup>,
              Songpengcheng Xia</a><sup>1,*</sup>,
              Lizhou Lin</a><sup>1</sup>,
              Lan Sun</a><sup>1</sup>,
              <br>
              Renwen Wang</a><sup>2</sup>,
              Jianran Liu</a><sup>2</sup>,
              Qi Wu</a><sup>2</sup>,
              Ling Pei</a><sup>1,&dagger;</sup>
            </h6>
            <p style="text-align: center">
              <sup>1</sup>Shanghai Jiao Tong University &nbsp;&nbsp;
              <sup>2</sup>Bytedance Research
              <br>
              <i><sup>*</sup>Equal contributions</i> <i><sup>&dagger;</sup>Corresponding author</i> 
            </p>
            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/abs/" role="button"  target="_blank">
                  <i class="fa fa-file"></i> Paper </a> </p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/Inowlzy/RadarLLM" role="button"  target="_blank">
                  <i class="fab fa-github"></i> Code & Data </a> </p>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="row" style="margin-bottom:5px">
            <div class="col" style="text-align:center">
              <img src="images/intro.png" width="90%">
            </div>
          </div>
          <div id="abstract" class="x-gradient-block">
            Millimeter-wave radar provides a  privacy-preserving solution for human motion analysis, yet its sparse point clouds pose significant challenges for semantic understanding. 
            We present Radar-LLM, the first framework that leverages large language models (LLMs) for human motion understanding using millimeter-wave radar as the sensing modality. 
            Our approach introduces two key innovations: (1) a motion-guided radar tokenizer based on our Aggregate VQ-VAE architecture that incorporates deformable body templates 
            and masked trajectory modeling to encode spatiotemporal point clouds into compact semantic tokens, and 
            (2) a radar-aware language model that establishes cross-modal alignment between radar and text in a shared embedding space. 
            To address data scarcity, we introduce a physics-aware synthesis pipeline that generates realistic radar-text pairs from motion-text datasets. 
            Extensive experiments demonstrate that Radar-LLM achieves state-of-the-art performance across both synthetic and real-world benchmarks, 
            enabling accurate translation of millimeter-wave signals to natural language descriptions. This breakthrough facilitates comprehensive motion understanding 
            in privacy-sensitive applications like healthcare and smart homes. We will release the full implementation to support further research.
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- pipeline -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title"><div class="x-gradient-font">Pipeline</div></div>
          <img src="images/pipeline.png" width="90%">
        </div>
      </div>
      <br>
      <p class="text-left">
        The overview of RadarLLM. We first encode radar point clouds into discrete tokens via a Motion-guided Radar Tokenizer. 
        The Radar-aware Language Model then aligns these tokens with textual representations in a shared embedding space through 
        joint optimization of unsupervised token reconstruction and supervised bidirectional radar-text translation.
      </p>
    </div>
  </section>

  <!-- tokenizer -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title"><div class="x-gradient-font">Radar Tokenizer</div></div>
          <img src="images/vq.png" width="90%">
        </div>
      </div>
      <br>
      <p class="text-left">
        Architecture and training pipeline of motion-guided radar tokenizer. 
        The Motion-guided Radar Tokenizer, built upon our Aggregate VQ-VAE architecture, compresses radar point cloud sequences 
        into discrete semantic tokens through point cloud sequence reconstruction and motion embedding learning.
      </p>
    </div>
  </section>

  <!-- virtualdata -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title"><div class="x-gradient-font">Virtual Data Generation</div></div>
            <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
              <source src="video/pcg.mp4" type="video/mp4">
            </video>
        </div>
      </div>
      <br>
      <p class="text-left">
        Virtual radar-text data generation pipeline. The Radar-Text dataset is constructed by simulating radar reflections 
        from SMPL motion sequences using ray tracing and signal processing techniques, based on existing motion-text datasets.
      </p>
     </div>
  </section>

  <!-- pcg results -->
<!--   <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title"><div class="x-gradient-font">Virtual Radar Point Cloud Results</div></div>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-steve video-grid1">
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
                <source src="video/v3.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
                <source src="video/v2.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
                <source src="video/v1.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
      <br>
      <!-- <p class="text-left">
        text
      </p> -->
<!--     </div>
  </section>
 --> -->
  <!-- qualitative results -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title">
            <div class="x-gradient-font">Qualitative Results</div>
          </div>
        </div>
      </div>
  
      <!-- Virtual Data Subsection -->
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title">
            <div class="x-gradient-font">Results on Virtual Data</div>
          </div>
          <div id="virtual-results-carousel" class="carousel results-carousel">
            <div class="item item-steve video-grid1">
              <video poster="" id="steve-gt-rgb" autoplay muted loop playsinline height="100%">
                <source src="video/dv5.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve-gt-rgb" autoplay muted loop playsinline height="100%">
                <source src="video/dv4.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve-gt-rgb" autoplay muted loop playsinline height="100%">
                <source src="video/dv3.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve-gt-rgb" autoplay muted loop playsinline height="100%">
                <source src="video/dv2.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve-gt-rgb" autoplay muted loop playsinline height="100%">
                <source src="video/dv1.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
  
      <br>
  
      <!-- Real Data Subsection -->
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title">
            <div class="x-gradient-font">Results on Real Data</div>
          </div>
          <div id="real-results-carousel" class="carousel results-carousel">
            <div class="item item-steve video-grid1">
              <video poster="" id="steve-gt-rgb" autoplay muted loop playsinline height="100%">
                <source src="video/dr1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve-gt-rgb" autoplay muted loop playsinline height="100%">
                <source src="video/dr2.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve-gt-rgb" autoplay muted loop playsinline height="100%">
                <source src="video/dr3.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve-gt-rgb" autoplay muted loop playsinline height="100%">
                <source src="video/dr4.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
  
      <br>
    </div>
  </section>

  <!-- comparisons -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title"><div class="x-gradient-font">Quantitative Results</div></div>
          <img src="images/comp.png" width="90%">
        </div>
      </div>
      <br>
      <p class="text-left">
        Comparison with state-of-the-art methods on virtual and real datasets.
      </p>
    </div>
  </section>

  <!-- citation -->
  <section>
  <div class="container">
    <div class="row ">
      <div class="col-12">
        <div class="x-section-title"><div class="x-gradient-font">Citation</div></div>
        <p class="bibtex x-gradient-block">
@InProceedings{shan2025mojito,
  title   = {RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence},
  author  = {Lai, Zengyuan and Yang, Jiarui and Xia, Songpengcheng and Lin, Lizhou and Sun, Lan and 
             Wang, Renwen and Liu, Jianran and Wu, Qi and Pei, Ling},
  journal = {arXiv preprint arXiv:xxxx.xxxxx},
  year    = {2025}
}
        </p>
      </div>
    </div>
  </div>
  </section>

  <!-- bottom bar -->
  <section>
  <div id="bottombar">
    <div><b>RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence</b></div>
    <div>Thanks to <a href="https://koyui.github.io/mojito/" target="_blank">Ziwei Shan</a> for the website template</div>
  </div>
  </section>

</html>
